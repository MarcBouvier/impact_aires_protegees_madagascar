[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Impact des aires protégées sur la déforestation à Madagascar",
    "section": "",
    "text": "Code\n# # Le package est en cours de développement, toujours installer la version en cours\nremotes::install_github(\"mapme-initiative/mapme.biodiversity\", \n                        upgrade = \"always\")\n\nlibrairies_requises <- c( # On liste les librairies dont on a besoin\n  \"dplyr\", # Pour faciliter la manipulation de données tabulaires\n  \"tidyr\", # Pour reformater les données (pivots...)\n  \"sf\", # Pour faciliter la manipulation de données géographiques\n  \"wdpar\", # Pour télécharger simplement la base d'aires protégées WDPA\n  \"tmap\", # Pour produire de jolies carte\n  \"geodata\", # Pour télécharger simplement les frontières administratives\n  \"tidygeocoder\", # pour obtenir les coordo GPS d'un point à partir de son nom\n  \"maptiles\", # Pour télécharger des fonds de carte \n  \"purrr\", # Pour utiliser des formes fonctionnelles de programmation (ex. map)\n  \"mapme.biodiversity\", # Acquisition et traitement des données du projet\n  \"plm\", # Linear Models for Panel Data and robust covariance matrices\n  \"stargazer\", # Reformater de manière plus lisible les résumé des régressions\n  \"MatchIt\", # Pour le matching\n  #\"glm\", # Modèles linéaires généralisés (pour le PSM)\n  \"optmatch\", # Fonctions d'optimisation du matching\n  \"cobalt\") # Tables et graphs d'équilibre des groupes de matching\n  \n# On regarde parmi ces librairies lesquelles ne sont pas installées\nmanquantes <- !(librairies_requises %in% installed.packages())\n# On installe celles qui manquent\nif(any(manquantes)) install.packages(librairies_requises[manquantes])\n# On charge toutes les librairies requises\ninvisible(lapply(librairies_requises, require, character.only= TRUE))\n\n# Système de coordonnées géographiques utilisées pour le projet : EPSG:29739\nmon_scr <- \"EPSG:29739\" # correspondant à Tananarive / UTM zone 39S\n# Surface des hexagones en km2\ntaille_hex <- 5\n# Taille des titres des cartes\ntaille_titres_cartes = 0.8\n# on crée un dossier de données si pas déjà disponible\ndir.create(\"data_s3\")\n# Désactiver les notations scientifiques\noptions(scipen =999)"
  },
  {
    "objectID": "index.html#idées-pour-la-structuration-du-cours",
    "href": "index.html#idées-pour-la-structuration-du-cours",
    "title": "Impact des aires protégées sur la déforestation à Madagascar",
    "section": "Idées pour la structuration du cours",
    "text": "Idées pour la structuration du cours"
  },
  {
    "objectID": "index.html#principe-dorganisation",
    "href": "index.html#principe-dorganisation",
    "title": "Impact des aires protégées sur la déforestation à Madagascar",
    "section": "Principe d’organisation",
    "text": "Principe d’organisation\nLes ateliers dureront 5 jours, suivis d’1/2 journée de restitution, avec 25 participants par atelier (~125 au total). On veillera à diviser l’atelier en sous-groupes en essayant d’avoir dans chaque groupe au moins un participant ayant quelques compétences économétrie et un participant capable de déchiffrer un texte en anglais.\nPour capter et retenir l’attention d’apprenants ayant des niveaux hétérogène, la proposition serait d’alterner des séances très spécifiques/concrètes avec des séances plus théoriques/méthodologiques. On pourrait ainsi avoir une approche itérative, avec une durée des sections qui reste à déterminer (entre 1/2 et 1 journée ?)."
  },
  {
    "objectID": "index.html#programme-première-ébauche-à-discuter",
    "href": "index.html#programme-première-ébauche-à-discuter",
    "title": "Impact des aires protégées sur la déforestation à Madagascar",
    "section": "Programme (première ébauche à discuter)",
    "text": "Programme (première ébauche à discuter)\nLe programme qui suit n’est qu’une proposition pour alimenter la réflexion collective :\n\nSection 1 - Définition des objectifs de l’évaluation (1/4 journée ?)\nQu’est-ce qu’une évaluation d’impact au sens économétrique du terme ? Quels sont les autres types d’évaluation et quelle est la différence ? Place centrale d’une question évaluative précise pour les évaluations d’impact : impact de quoi (intervention), sur qui (groupe de traitement), sur quoi (variable de résultat). Les EI évaluent un mode d’intervention, pas un projet en particulier : enjeux de validité interne et validité externe.\n\nExercice : Formuler des questions se prêtant à une évaluation d’impact sur des enjeux de conservation.\nDiscussion : Approches évaluatives différentes qu’on peut porter avec d’autres méthodes (approches quali ou évaluation “classique”).\n\n\nSynthèse : introduction succincte au formalisme des équations et aux DAG.\n\n\n\nSéance 2 - Recherche bibliographique (1/4 journée ?)\nCompte tenu de la portée générale des EI, il n’est pas pertinent de les mener pour chaque projet/situation particulière : il est donc essentiel de commencer par une bonne revue de littérature pour savoir si le mode d’intervention qui nous intéresse a déjà été évalué dans un contexte analogue. Cette session présente les outils et méthodes de revue de littérature applicables aux évaluations d’impact.\nGoogle Scholar : présentation de l’outil et recommandations pour trouver des évaluations d’impact pertinentes (recherche avancée, similaires et citations).\n\nExercice : utiliser Google Scholar pour mener une revue de littérature sur le thème de l’impact des aires protégées, au niveau mondial, régional (ex. Afrique) ou national (Madagascar)\n\nPrésentation des bases d’évaluation d’impact (p. ex. Campbell Collaboration). Focus sur la base d’évaluations d’impact du 3IE.\n\nExercice : explorer l’evidence gap map du sur la conservation des forêts : https://gapmaps.3ieimpact.org/evidence-maps/forest-conservation-gap-map - revue de littérature.\n\n\nSynthèse théorique : Présentation rapide des revues systématiques ;: méthode, portée et limites.\n\n\n\nSéance 3 - étude d’articles et synthèse (1/2 journée ?)\nLes formateurs distribuent aux participant un article court sur l’évaluation de l’impact des aires protégées sur la déforestation. Les apprenants le lisent. Les formateurs en font une synthèse en renseignant plusieurs critères : discipline des auteurs, périmètre de l’étude, données mobilisées, unités comparées, taille d’échantillon, méthode, spécifications du modèle (variable de traitement, de contrôle, et de résultat), résultat.\n\nExercice : les étudiants se voient chacun remettre un article (en français) et remplir la ligne\n\n\nSynthèse théorique : tableau complété de revue de la littérature.\n\n\nEvaluations de l’impact des aires protégées sur la déforestation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRéférence\nTitre\nDiscipline\nPérimètre\nDonnées\nUnités\nEchantillon\nMéthode\nTraitement\nOutcomes\nContrôles\nRésultats\n\n\n\n\n(Spracklen et al. 2015)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(Joppa and Pfaff 2011)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(Desbureaux 2016)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(Gimenez 2012)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(Nelson and Chomitz 2011)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(Waeber et al. 2016)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# On initie un tableau vide\nrevue_litt <- tibble::tibble(\n  `Référence` = character(),\n  `Titre` = character(),\n  `Discipline des auteurs` = character(),\n  `Périmètre d'analyse` = character(),\n  `Données mobilisées` = character(),\n  `Unités comparées` = character(),\n  `Taille d'échantillon` = character(),\n  `Méthode d'attibution` = character(),\n  `Variable de traitement` = character(),\n  `Variables de contrôle` = character(),\n  `Variable de résultat` = character(),\n  `Résultats`= character())\n\n# On remplit autant de \"fiches\" que de références pour composer le tableau final\nrevue_litt <- revue_litt %>% add_row(\n  `Référence` = \"\",\n  `Titre` = \"\",\n  `Discipline des auteurs` = \"\",\n  `Périmètre d'analyse` = \"\",\n  `Données mobilisées` = \"\",\n  `Unités comparées` = \"\",\n  `Taille d'échantillon` = \"\",\n  `Méthode d'attibution` = \"\",\n  `Variable de traitement` = \"\",\n  `Variables de contrôle` = \"\",\n  `Variable de résultat` = \"\",\n  `Résultats`= \"\")\n\n\n\n\nSéance 4 - Sources de données (1/2 journée ?)\nOuvrir les participants sur la diversité des données qui peuvent être mobilisées pour évaluer l’impact de solutions, projets ou politiques publiques : données d’enquêtes, recensements, systèmes d’information (administratifs/gestion), données satellitaires, nouveaux jeux composites. Avantage et limites de ces sources de données. Présentation de sources potentielles : IHSN, institut national de statistique, Protected Planet, FAO… (préparer un tableau de synthèse ?)\n\nExercice : recherche de source de données pertinentes pour étudier l’impact des aires protégées sur la déforestation.\n\nPrésentation d’outils facilitant la collecte : Google Earth Engine (catalogue) et mapme.biodiversity (Görgen and Bhandari 2022).\n\nExercice : essai de recherche de données.\n\n\nSynthèse : enjeux de compatibilité des mailles spatiales, temporelles, unités…\n\n\n\nSéance 5 - Traitement des données (1 jour ?)\nPrésentation des principaux logiciels/langages : R, Python, Stata, Google Earth Engine, et ressources pour l’auto-formation.\n\nDiscussions : expériences et avantanges/inconvénients des logiciels à base de code.\n\nFocus sur R : langages, librairies, ressources, types de documents de travail (R, RMarkdown, Quarto, Shiny…) et documents en sortie (présentations, LaTeX/pdf, html, Word, applications interactives…).\n\nExercice : prise en main de R, premier rendus\n\nPrésentation de l’étude de cas sur les aires protégées à Madagascar : section “Traitement de données” plus bas.\n\n\nSéance 6 - analyse de données (2 jours ?)\nReprise des différentes approches d’inférence causale. Focus sur les méthodes de matching. Présentation de l’approche “naïve” de matching.\n\nDiscussion : interprétation du code exécuté.\nExercice : que faut-il comparer avec quoi.\n\nPrésentation des principes de base du matching.\n\nExercice : lister les méthodes de matching.\n\nComparaison des résultats en sortie.\n\nSynthèse : importance d’avoir une discussion de fond : ATT, ATE, sélection des approches, validation.\n\n\n\nSéance 7 - Interprétation des résultats et discussion (1/2 journée ?)"
  },
  {
    "objectID": "index.html#environnement-et-paramétrages",
    "href": "index.html#environnement-et-paramétrages",
    "title": "Impact des aires protégées sur la déforestation à Madagascar",
    "section": "Environnement et paramétrages",
    "text": "Environnement et paramétrages\nL’analyse est réalisée en R, qui est à la fois un logiciel et un langage open sources dédiés à l’analyse de données. Les traitements sont réalisés en Rmarkdown. Le même code source peut générer un rendu en LaTeX/PDF, HTML ou Word.\nOn réutilise en partie le code publié par Johannes Schielein: Jochen Kluve, Johannes Schielein, Melvin Wong, Yota Eilers, The KfW Protected Areas Portfolio: a Rigorous Impact Evaluation, KfW, 2022-07-08.\nOn s’appuie sur le package R {mapme.biodiversity}, développé par la KfW dans le cadre de l’initiative commune MAPME qui associe la KfW et l’AFD. Le package {mapme.biodiversity} facilite l’acquisition et la préparation d’un grand nombre de données (CHIRPS, Global Forest Watch, FIRMS, SRTM, Worldpop…) et calculer un grand nombre d’indicateurs de manière harmonisée (active_fire_counts, biome classification, land cover classification, population count, precipitation, soil properties, tree cover loss, travel time…). Une documentation riche est disponible sur le portail dédié du package en question.\nOn mobilise aussi les codes d’analyse d’impact développés par la même équipe et mise à disposition dans le dépôt Github: https://github.com/openkfw/mapme.protectedareas. Le code développé par l’équipe est assez complexe. A des fins pédagogiques et pour s’assurer qu’on l’a bien compris, on propose ici une version simplifiée (en cours de développement)\nLes sources pour l’ensemble du code source et du texte du présent document est accessible sur Github à l’adresse suivante : https://github.com/fBedecarrats/deforestation_madagascar. Les analyses sont menées sur la plateforme SSP Cloud, mise à disposition par l’INSEE pour les data scientist travaillant pour des administrations publiques. Il s’agit d’une instance de stockage de données massif (S3) et de calcul haute performance (cluster Kubernetes) disposant d’une interface simplifiée permettant à l’utilisateur de configurer, lancer et administrer facilement des environnements de traitement de données (RStudio server, Jupyter lab ou autres…). Le code est conçu pour s’exécuter de la même manière en local sur un PC, mais la préparation des données sera certainement beaucoup plus longue à exécuter."
  },
  {
    "objectID": "index.html#préparation-des-données",
    "href": "index.html#préparation-des-données",
    "title": "Impact des aires protégées sur la déforestation à Madagascar",
    "section": "Préparation des données",
    "text": "Préparation des données\nLes données spatialisées à croiser son, pour certaines, des données vectorielles (aires protégées, frontières administratives) et, pour d’autres, des données matricielles (“raster data”, en anglais).\n\nAires protégées\nLes données d’aires protégées sont issues de la base WDPA, consultable en ligne sur protectedplanet.org.\n\n\nCode\n# Ce qui suit jusqu'à la commande \"save\" ne s'execute que si le résultat n'a pas\n# déjà été généré lors d'une exécution précédente.\nif (file.exists(\"data_s3/aires_prot_mada.rds\")) {\n  load(\"data_s3/aires_prot_mada.rds\")\n} else {\n  # Téléchargement et chargement dans R des données d'aires protégées malgaches\n  aires_prot_mada <- wdpa_fetch(\"Madagascar\", wait = TRUE,\n                                download_dir = \"data_s3/WDPA\") %>%\n    st_transform(crs = mon_scr) %>%\n    filter(STATUS != \"Proposed\") %>%\n    filter(DESIG != \"Locally Managed Marine Area\", DESIG != \"Marine Park\") \n  \n  # Téléchargement du contour des zones émergées de Madagascar\n  contour_mada <- gadm(country = \"Madagascar\", resolution = 1, level = 0,\n                       path = \"data_s3/GADM\") %>%\n    st_as_sf() %>% \n    st_transform(crs = mon_scr)\n  # On sauve les objets créés pour ne pas avoir à refaire cette étape\n  save(aires_prot_mada, contour_mada, file = \"data_s3/aires_prot_mada.rds\")\n}\n\ntb <- aires_prot_mada %>%\n  filter(STATUS != \"Proposed\", MARINE != 2) %>%\n  mutate(decennie_creation = STATUS_YR -  STATUS_YR %% 10,\n       strict = IUCN_CAT %in% c(\"I\", \"II\", \"III\", \"IV\"),\n       surface_terrestre = REP_AREA - REP_M_AREA) %>%\n  group_by(decennie_creation, strict) %>%\n  summarise(N = n(),\n            aire_totale = sum(surface_terrestre, na.rm = TRUE))\n\n# On génère un rendu cartographique\ntm_shape(contour_mada) +\n  tm_polygons() +\n  tm_shape(filter(aires_prot_mada)) + \n  tm_polygons(col = \"IUCN_CAT\", alpha = 0.6, title = \"Catégorie IUCN\") +\n  # NB : on note les positions en majuscules quand on veut coller aux marges\n  tm_credits(\"Sources: WDPA et GADM\", position = c(\"RIGHT\", \"BOTTOM\"),\n             size = 0.6) +\n  tm_layout(main.title = \"Aires protégées de Madagascar\",\n            # NB : position en minuscules pour laisser un espace avec la marge\n            main.title.position = c(\"center\", \"top\"),\n            main.title.size = taille_titres_cartes,\n            legend.position = c(\"left\", \"top\"),\n            legend.outside = TRUE)\n\n\n\n\n\nCertaines améliorations doivent encore être apportées, pour préciser notamment la date de création ou le statut de certaines aires => A travailler avec Jeanne notamment.\nIl faut aussi s’assurer qu’on filtre bien les entitées analysées selon un criète pertinent. Actuellement, on ne garde que les aires qui ont encore un statut “proposed” et on exclut les aires marines. Il pourrait toutefois sembler utile d’écarter les aires dont le statut de protection est considéré comme trop faible. Il pourrait aussi être pertinent de ne garder que les aires protégées comportant un niveau minimum de couvert forestier : autrement, cela signifie que la forêt n’est pas un habitat pertinent pour les écosystèmes que la démarche de conservation cherche à protéger dans cette aire.\n\n\nDonnées satellitaires\nIci le package mapme.biodiversity développé par la KfW est particulièrement utile pour l’analyse. Il automatise en large partie le processus d’acquisition de données brutes issu de sources divers et le calcul d’indicateurs pour des périmètres définies (ici, les 120 612 hexagones du maillage du territoire malgache). Ce processus est toutefois très gourmand en ressources et on l’a réalisé sur un environnement de calcul haute performance (la plateforme SSP Cloud de l’INSEE). Les résultats de ces traitements ont été enregistrés et il ne semble pas pertinent/utile de demander aux apprenants de le refaire, ce serait beaucoup trop long.\n\n\nCode\n# Ce qui suit jusqu'à la commande \"save\" ne s'execute que si le résultat n'a pas\n# déjà été généré lors d'une exécution précédente.\nif (file.exists(\"data_s3/grille_mada_donnees_raster.rds\")) {\n  load(\"data_s3/grille_mada_donnees_raster.rds\")\n} else {\n  \n  # Création d'un maillage du territoire émergé --------------------------------\n  \n  # On crée un cadre autour des aires protégées du pays\n  cadre_autour_mada = st_as_sf(st_as_sfc(st_bbox(aires_prot_mada)))\n  \n  # Cellules de 5km de rayon\n  surface_cellule <- taille_hex * (1e+6)\n  taille_cellule <- 2 * sqrt(surface_cellule / ((3 * sqrt(3) / 2))) * sqrt(3) / 2\n  grille_mada <- st_make_grid(x = cadre_autour_mada,\n                              cellsize = taille_cellule,\n                              square = FALSE)\n  # On découpe la grille pour ne garder que les terres émergées\n  cellules_emergees <- st_intersects(contour_mada, grille_mada) %>%\n    unlist()\n  grille_mada <- grille_mada[sort(cellules_emergees)] %>%\n    st_sf()\n  \n  # Traitement des données satellitaires avec {mapme.bidiversity}---------------\n  \n  # Constitution d'un portefeuille (voir la documentation)\n  grille_mada <- init_portfolio(x = grile_mada, \n                                years = 2000:2020,\n                                outdir = \"data_s3/mapme\",\n                                cores = 24,\n                                add_resources = TRUE,\n                                verbose = TRUE)\n  \n  # Acquisition des données satellitaires requises (rasters) ------------------- \n  # Données d'accessibilité de Nelson et al. (2018)\n  grille_mada <-  get_resources(x = grille_mada, resource = \"nelson_et_al\",  \n                                range_traveltime = \"5k_110mio\")\n  # Données de qualité des sols (uniquement teneur )\n  grille_mada <-  get_resources(x = grille_mada,\n                                resources = \"soilgrids\",  layers = \"clay\", \n                                depths = \"5-15cm\", stats = \"mean\")\n  # Données sur le couvert forestier de Global Forest Watch\n  grille_mada <- get_resources(x = grille_mada, \n                               resources = c(\"gfw_treecover\", \"gfw_lossyear\", \n                                             \"gfw_emissions\"))\n  # Modèle numérique de terrain SRTM de la NASA\n  grille_mada <- get_resources(x = grille_mada, resource = \"nasa_srtm\")\n  # Données de feux\n  grille_mada <- get_resources(x = grille_mada, resource = \"nasa_firms\",\n                               instrument = \"MODIS\")\n  \n  # Calcul des indicateurs -----------------------------------------------------\n  \n  # Indicateurs d'accessibilité\n  grille_mada <- calc_indicators(x = grille_mada,\n                                 \"traveltime\",  stats_accessibility = \"mean\",\n                                 engine = \"extract\")\n  # Indicateurs de sols\n  \n  grille_mada <- calc_indicators(x = grille_mada,\n                                 \"soilproperties\", stats_soil = \"mean\", \n                                 engine = \"extract\")\n \n   # Indicateurs de couvert forestier\n  grille_mada <- calc_indicators(x = grille_mada,\n                                 indicators = \"treecover_area_and_emissions\", \n                                 min_cover = 10, min_size = 1)\n  # Indicateurs de relief de terrain\n  grille_mada <- calc_indicators(x = grille_mada,\n                               indicators = c(\"tri\", \"elevation\"),\n                               stats_tri = \"mean\", stats_elevation = \"mean\")\n  # Indicateurs d'incendies\n  grille_mada <- calc_indicators(x = grille_mada,\n                                 \"active_fire_counts\")\n  grille_mada <- calc_indicators(x = grille_mada,\n                                 \"active_fire_properties\")\n  \n  # Sauvegarde du résultat\n  save(grille_mada, file = \"data_s3/grille_mada_donnees_raster.rds\")\n}\n\n\nLe maillage est trop fin pour être visible à l’échelle du pays, mais on peut l’observer en zoomant sur une zone spécifique.\n\n\nCode\n# On compte le nombre d'hexagones\nn_hex <- length(grille_mada)\n# Carte pour visualiser le résultat --------------------------------------------\n\n## Carte de droite : zoom sur une zone spécifique-------------------------------\n# On part d'un dataframe contenant une adresse\nnom_centre_zoom <- \"Maroantsetra\"\nzoom_centre <- data.frame(address = nom_centre_zoom) %>%\n  geocode(address, method = \"osm\") %>% # on retrouve sa localisation xy\n  select(long, lat) %>% # on ne garde que le xy\n  as.numeric() %>% # qu'on passe en format numérique attendu par st_point\n  st_point() %>% # On le spécifie en point\n  st_sfc(crs = \"EPSG:4326\") \n\n# On crée une boîte de 100km \nzoom_boite <- zoom_centre %>% # On repart du centre\n  st_buffer(dist = 50000) %>% # On crée un cercle de 50km de rayon\n  st_make_grid(n = 1) \n\n# On filtre les alvéoles pour ne garder que celles qui sont dans le zoom\ngrille_zoom <- st_intersection(grille_mada, zoom_boite)\n\n# On télécharge un fond de carte pour la carte de droite\nfond_carte_zoom <- get_tiles(zoom_boite, provider = \"Stamen.Terrain\", \n                             zoom = 10, crop = TRUE)\n# On génère la carte de droite\ncarte_zoom <- tm_shape(fond_carte_zoom) + \n  tm_rgb() +\n  tm_shape(grille_zoom) +\n  tm_borders() +\n  tm_shape(zoom_boite) + \n  tm_borders(col = \"red\") +\n  tm_layout(frame = FALSE,\n            main.title = paste(\"Zoom sur la zone de\", nom_centre_zoom),\n            main.title.size = taille_titres_cartes) +\n  tm_credits(get_credit(\"Stamen.Toner\"),\n             bg.color = \"white\",\n             align = \"right\",\n             position = c(\"right\", \"BOTTOM\"))\n\n## Carte de gauche : simple à réaliser mais hexagones non visibles -------------\ncarte_grille <- tm_shape(grille_mada) +\n  tm_polygons() + \n  tm_shape(zoom_boite) +\n  tm_borders(col = \"red\") +\n  tm_layout(frame = FALSE) +\n  tm_layout(main.title = paste(\"Découpage en\", n_hex,\n                               \"hexagones de\", taille_hex*2, \"km2\"),\n            main.title.size = taille_titres_cartes)\n\n# Assemblage des deux cartes ---------------------------------------------------\ntmap_arrange(carte_grille, carte_zoom, ncol = 2) \n\n\n\n\n\nOn peut également représenter les différentes valeurs des indicateurs générés à partir des données satellitaires.\n\n\nCode\nif (file.exists(\"data_s3/grille_mada_summary.rds\")) {\n  load(\"data_s3/grille_mada_summary.rds\")\n} else {\n  grille_mada_summary <- grille_mada %>%\n    # On met à plat les données de distance\n    unnest(cols = c(traveltime, soilproperties, tri, elevation),\n           names_repair = \"universal\") %>%\n    select(-distance, -layer, -depth, -stat,  -active_fire_counts, \n           -active_fire_properties) %>%\n    rename(distance_minutes_5k_110mio = minutes_mean, mean_clay_5_15cm = mean) \n  \n  grille_mada_summary <- grille_mada_summary %>%\n    unnest(cols = treecover_area_and_emissions) %>%\n    pivot_wider(names_from = \"years\", values_from = c(\"treecover\", \"emissions\")) %>%\n    mutate(var_treecover = (treecover_2020 - treecover_2000)/treecover_2000,\n           sum_emissions = rowSums(across(starts_with(\"emission\")), na.rm = T)) %>%\n    rename(init_treecover_2000 = treecover_2000) %>% # pour le garder\n    select(-starts_with(\"treecover\"), -starts_with(\"emission\")) %>%\n    rename(treecover_2000 = init_treecover_2000) %>%\n    relocate(geometry, .after = last_col())\n  \n  save(grille_mada_summary, file = \"data_s3/grille_mada_summary.rds\")\n}\n\ncarte_acces <- tm_shape(grille_mada_summary) +\n  tm_fill(\"distance_minutes_5k_110mio\",\n          title = \"Distance ville (>5K hab)\",\n          palette = \"Oranges\",\n          style = \"fisher\",\n          n = 8,\n          legend.hist = TRUE) +\n  tm_layout(legend.outside = TRUE,\n            # legend.title.size = 0.8,\n            # legend.text.size = 0.6,\n            legend.hist.width = 1,\n            legend.hist.height = 1)\n\ncarte_sol <- tm_shape(grille_mada_summary) +\n  tm_fill(\"mean_clay_5_15cm\",\n          title = \"Sol argileux (5-15cm prof)\",\n          palette = \"YlOrBr\",\n          n = 8,\n          legend.hist = TRUE) +\n  tm_layout(legend.outside = TRUE,\n            # legend.title.size = 0.8,\n            # legend.text.size = 0.6\n            legend.hist.width = 1,\n            legend.hist.height = 1)\n\ncarte_TRI <- tm_shape(grille_mada_summary) +\n  tm_fill(\"tri_mean\",\n          title = c(\"Terrain accidenté (TRI)\"),\n          palette = \"Blues\",\n          n = 8,\n          legend.hist = TRUE) +\n  tm_layout(legend.outside = TRUE,\n            # legend.title.size = 0.8,\n            # legend.text.size = 0.6,\n            legend.hist.width = 1,\n            legend.hist.height = 1)\n\ncarte_alt <- tm_shape(grille_mada_summary) +\n  tm_fill(\"elevation_mean\",\n          title = \"Altitude\",\n          palette = \"Purples\",\n          n = 8,\n          legend.hist = TRUE) +\n  tm_layout(legend.outside = TRUE,\n            # legend.title.size = 0.8,\n            # legend.text.size = 0.6,\n            legend.hist.width = 1,\n            legend.hist.height = 1)\n\ncarte_cover <- graph_alt <- tm_shape(grille_mada_summary) +\n  tm_fill(\"treecover_2000\",\n          title = \"Couvert arboré en 2000\",\n          palette = \"Greens\",\n          n = 8,\n          legend.hist = TRUE) +\n  tm_layout(legend.outside = TRUE,\n            # legend.title.size = 0.8,\n            # legend.text.size = 0.6,\n            legend.hist.width = 1,\n            legend.hist.height = 1)\n\ncarte_loss <- graph_alt <- tm_shape(grille_mada_summary) +\n  tm_fill(\"var_treecover\",\n          title = \"Perte couvert (2000-2020)\",\n          palette = \"Reds\",\n          n = 8,\n          legend.hist = TRUE) +\n  tm_layout(legend.outside = TRUE,\n            # legend.title.size = 0.8,\n            # legend.text.size = 0.6,\n            legend.hist.width = 1,\n            legend.hist.height = 1)\n\ntmap_arrange(carte_acces, carte_sol, \n             carte_alt, carte_TRI, \n             carte_cover, carte_loss,\n             ncol = 2, nrow = 3) \n\n\n\n\n\nOn notera que plusieurs autres indicateurs peuvent être calculés à partir du pabkage mapme.biodiversity:\n\nactive_fire_counts: Calculate active fire counts based on NASA FIRMS polygonsactive_fire_properties: Calculate active fire properties based on NASA FIRMS polygons\nbiome: Calculate biomes statistics (TEOW) based on WWF\ndrought_indicator: Calculate drought indicator statistics\necoregion: Calculate terrestrial ecoregions statistics (TEOW) based on WWF\nlandcover: Calculate area of different landcover classes\nmangroves_area: Calculate mangrove extent based on Global Mangrove Watch (GMW)\npopulation_count: Calculate population count statistics (Worldpop)\nprecipitation_chirps: Calculate precipitation statistics based on CHIRPS\nprecipitation_wc: Calculate precipitation statistics\nsoilproperties: Calculate Zonal Soil Properties\ntemperature_max_wc: Calculate maximum temperature statistics\ntemperature_min_wc: Calculate minimum temperature statistics based on WorldClim\ntraveltime: Calculate accessibility statistics\ntreecover_area: Calculate treecover statistics\ntreecover_area_and_emissions: Calculate treeloss statistics\ntreecoverloss_emissions: Calculate emission statistics\ntri: Calculate Terrain Ruggedness Index (TRI) statistics\n\n\n\nCroisement des données d’aires protégées et satellitaires\nOn peut maintenant associer les données d’aires protégées aux hexagones afin de les croiser avec les indicateurs issus des données satellitaries déjà calculés pour ces hexagones.\n\n\nCode\nif (file.exists(\"data_s3/grille_mada_summary_AP.rds\")) {\n  load(\"data_s3/grille_mada_summary_AP.rds\")\n} else {\n  # Le code suivant va asocier les hexagones aux aires protégées en se référant\n  # aux AP par leur rang dans la table des AP. On voudra plutôt leur identifiant, \n  # alors on crée une table d'équivalence rang/identifiant \n  aires_prot_mada_rang_id <- aires_prot_mada %>%\n    st_drop_geometry() %>% # Enlève l'information spatiale\n    mutate(AP_ligne = row_number()) %>% # Intègre le numéro de ligne dans un champ\n    select(AP_ligne, WDPAID) # On ne garde que le numéro de ligne et l'identifiant\n  \n  # Pour chaque hexagone, on va maintenant identifier s'ils touchent (\"intersect\")\n  # ou s'ils sont strictiement inclus dans (\"within\") une aire protégé\n  grille_mada_summary_AP <- grille_mada_summary %>%\n    st_transform(crs = mon_scr) %>%\n    mutate(AP_ligne = st_intersects(., aires_prot_mada), # liste des n° de lignes d'AP qui recoupent\n           AP_ligne = map(AP_ligne, 1), # On extrait le 1° élément de la liste (toutes n'ont qu'1 élément)\n           AP_ligne = as.integer(as.character(AP_ligne))) %>%  # formattage en numérique\n    left_join(aires_prot_mada_rang_id, by = \"AP_ligne\") %>% # récupère l'id de l'AP\n    rename(WDPAID_touche = WDPAID) %>% # on renomme pour différentier\n    mutate(AP_ligne = st_within(., aires_prot_mada),\n           AP_ligne = map(AP_ligne, 1),\n           AP_ligne = as.integer(as.character(AP_ligne))) %>%\n    left_join(aires_prot_mada_rang_id, by = \"AP_ligne\") %>%\n    rename(WDPAID_inclus = WDPAID) %>%\n    select(-AP_ligne) \n  \n  grille_mada_summary_AP <- grille_mada_summary_AP %>%\n    st_sf() %>%\n    mutate(position_ap = ifelse(is.na(WDPAID_touche), \"Extérieur\",\n                                ifelse(!is.na(WDPAID_inclus), \"Intérieur\",\n                                       \"Frontière\"))) %>%\n    relocate(geometry, .after = last_col()) \n  save(grille_mada_summary_AP, file = \"data_s3/grille_mada_summary_AP.rds\")\n  haven::write_dta(st_drop_geometry(grille_mada_summary_AP), \n                   path = \"data_s3/grille_mada_summary_AP.dta\")\n}\n\n# Une vue après classification\ntm_shape(grille_mada_summary_AP) +\n  tm_fill(col = \"position_ap\", title = \"par rapport aux aires protégées\") +\n  tm_layout(main.title = \"Localisation des hexagones\",\n            # NB : position en minuscules pour laisser un espace avec la marge\n            main.title.position = c(\"center\", \"top\"),\n            main.title.size = taille_titres_cartes,\n            legend.position = c(\"left\", \"top\"),\n            legend.outside = FALSE)\n\n\n\n\n\nEn plus d’un format natif R (rds), on a aussi enregistré l’export au format Stata (.dta)"
  },
  {
    "objectID": "index.html#estimation-de-limpact",
    "href": "index.html#estimation-de-limpact",
    "title": "Impact des aires protégées sur la déforestation à Madagascar",
    "section": "Estimation de l’impact",
    "text": "Estimation de l’impact\nPremière approche d’appariement “naïve”\nUne procédure détaillée est proposée dans https://github.com/openkfw/mapme.protectedareas\nOn commence ici par une approche naïve, dans le sens où on apparie simplement les zones dans les aires protégées avec les zones hors aires protégées pour expliquer le principe du matching (“appariement”, en français). On verra ensuite que cette approche est trop simpliste pour être valide et qu’il faut réfléchir à la population cible, aux variables d’appariement et au recouvrement entre les groupes de traitement et de contrôle.\n\n\nCode\n# On référence le nom des variables qui vont servir à l'analyse\nvariables_analyse <- c(\"assetid\",\"treatment\",\"distance_minutes_5k_110mio\",\n                       \"tri_mean\", \"elevation_mean\", \"mean_clay_5_15cm\",\n                       \"treecover_2000\", \"var_treecover\")\n# On renomme le ficher 'df' (dataframe) : plus concis dans les commandes ensuite\ndf <- grille_mada_summary_AP %>%\n  # On supprime toutes les lignes pour lesquelles au moins 1 valeur variable \n  # est manquante parmi les variables d'analyse\n  drop_na(any_of(variables_analyse)) %>%\n  mutate(treatment = position_ap == \"Intérieur\")\n  \n\n# Get propensity scores\nglm_out <- glm(treatment ~ \n                 distance_minutes_5k_110mio + \n                 mean_clay_5_15cm + \n                 tri_mean +\n                 elevation_mean + \n                 treecover_2000,  # Très étrange\n               family = binomial(link = \"probit\"),\n               data = df)\n\nstargazer(glm_out,\n          summary = TRUE,\n          type = \"text\",\n          title = \"Probit regression for matching frame \")\n\n\n\nProbit regression for matching frame\n======================================================\n                               Dependent variable:    \n                           ---------------------------\n                                    treatment         \n------------------------------------------------------\ndistance_minutes_5k_110mio          0.0004***         \n                                    (0.00003)         \n                                                      \nmean_clay_5_15cm                    -0.042***         \n                                     (0.002)          \n                                                      \ntri_mean                            0.015***          \n                                     (0.001)          \n                                                      \nelevation_mean                      0.0003***         \n                                    (0.00002)         \n                                                      \ntreecover_2000                      0.002***          \n                                    (0.00004)         \n                                                      \nConstant                            -1.449***         \n                                     (0.043)          \n                                                      \n------------------------------------------------------\nObservations                         117,610          \nLog Likelihood                     -23,367.050        \nAkaike Inf. Crit.                  46,746.090         \n======================================================\nNote:                      *p<0.1; **p<0.05; ***p<0.01\n\n\nCode\nm_out <- matchit(treatment ~ \n                   distance_minutes_5k_110mio + \n                   mean_clay_5_15cm + \n                   tri_mean +\n                   elevation_mean + \n                   treecover_2000,\n                 data = df,\n                 method = \"nearest\",\n                 replace = TRUE,\n                 # exact = ~ as.factor(NAME_0),\n                 distance = \"glm\", \n                 discard = \"both\", # common support: drop units from both groups \n                 link = \"probit\")\n\nprint(m_out)\n\n\nA matchit object\n - method: 1:1 nearest neighbor matching with replacement\n - distance: Propensity score [common support]\n             - estimated with probit regression\n - common support: units from both groups dropped\n - number of obs.: 117610 (original), 12731 (matched)\n - target estimand: ATT\n - covariates: distance_minutes_5k_110mio, mean_clay_5_15cm, tri_mean, elevation_mean, treecover_2000\n\n\nCode\n# print(summary(m_out, un = FALSE))\nbal_table <- bal.tab(m_out, un = TRUE)\nprint(bal_table)\n\n\nCall\n matchit(formula = treatment ~ distance_minutes_5k_110mio + mean_clay_5_15cm + \n    tri_mean + elevation_mean + treecover_2000, data = df, method = \"nearest\", \n    distance = \"glm\", link = \"probit\", discard = \"both\", replace = TRUE)\n\nBalance Measures\n                               Type Diff.Un Diff.Adj\ndistance                   Distance  0.6743   0.0001\ndistance_minutes_5k_110mio  Contin.  0.3110  -0.0441\nmean_clay_5_15cm            Contin.  0.0229  -0.0025\ntri_mean                    Contin.  0.4029  -0.0306\nelevation_mean              Contin.  0.2753  -0.0022\ntreecover_2000              Contin.  0.7104   0.0262\n\nSample sizes\n                       Control Treated\nAll                  110951.      6659\nMatched (ESS)          5439.42    6650\nMatched (Unweighted)   6081.      6650\nUnmatched            104721.         0\nDiscarded               149.         9\n\n\nCode\nm_data <- match.data(m_out) %>%\n  st_sf()\n# On visualise les données appareillées\ntm_shape(contour_mada) +\n  tm_borders() +\n  tm_shape(m_data) +\n  tm_fill(col = \"treatment\", palette = \"Set1\", title = \"Groupes d'appariement\",\n          labels = c(\"Contrôle\", \"Traitement\")) +\n  tm_layout(legend.outside = TRUE,\n            main.title = \"Localisation des groupes de traitement et de contrôle\",\n            main.title.position = c(\"center\", \"top\"),\n            main.title.size = taille_titres_cartes)\n\n\n\n\n\nPremière approche : critiquer la méthode employée ici.\n\nPistes d’amélioration\n\nExclure les Aires protégées avant 2000, voire 2003.\nOn pourrait éventuelement prendre comme variables de contrôle le couvert forestier en 2000 et le taux de couverture entre 2000 et 2003.\nGros problème : toutes les aires protégées créées à partir de 2003 n’ont pas de\nSchielein et al. excluent UNESCO MAB Biosphere reserves: pourquoi ?"
  }
]